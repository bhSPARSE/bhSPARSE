<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="bhSPARSE : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>bhSPARSE</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/bhSPARSE/bhSPARSE">View on GitHub</a>

          <h1 id="project_title">bhSPARSE</h1>
          <h2 id="project_tagline"></h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/bhSPARSE/bhSPARSE/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/bhSPARSE/bhSPARSE/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="bhsparse-a-sparse-blas-library" class="anchor" href="#bhsparse-a-sparse-blas-library" aria-hidden="true"><span class="octicon octicon-link"></span></a>bhSPARSE: A Sparse BLAS Library</h1>

<p><br></p><hr>

<h3>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h3>

<p>The bhSPARSE provides basic linear algebra subroutines (BLAS) used for sparse matrix computations on heterogeneous parallel processors. Currently, the bhSPARSE library only supports general sparse matrix-matrix multiplication (SpGEMM) operation, using an algorithm described in paper: Weifeng Liu and Brian Vinter, "An Efficient GPU General Sparse Matrix-Matrix Multiplication for Irregular Data," Parallel and Distributed Processing Symposium, 2014 IEEE 28th International (IPDPS '14), pp.370-381, 19-23 May 2014, <a href="http://dx.doi.org/10.1109/IPDPS.2014.47">Link</a>.</p>

<p>Contact: Weifeng Liu (weifeng.liu <em>at</em> nbi.ku.dk) and/or Brian Vinter (vinter <em>at</em> nbi.ku.dk).</p>

<p>Other sparse BLAS routines are in preparation.</p>

<p><br></p><hr>

<h3>
<a id="branches" class="anchor" href="#branches" aria-hidden="true"><span class="octicon octicon-link"></span></a>Branches</h3>

<p>Now bhSPARSE has two separate branches: CUDA and OpenCL. The CUDA version requires an nVidia GPU, CUDA SDK and CUSP library. The OpenCL version only needs an OpenCL-enabled GPU and OpenCL compiling environment. </p>

<p><br></p><hr>

<h3>
<a id="preparation" class="anchor" href="#preparation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparation</h3>

<p>To use this SpGEMM program, the first thing you need to do is to change the 'Makefile' with correct CUDA installation path and OpenCL libs path. Further, if you are using a CUDA device, check its compute capability (e.g., 3.5, 5.0 or above) and change item like '-arch=sm_35' if needed. Then you can build the code.</p>

<p><br></p><hr>

<h3>
<a id="execution" class="anchor" href="#execution" aria-hidden="true"><span class="octicon octicon-link"></span></a>Execution</h3>

<p>This program executes C=AB operation, where A, B and C are all sparse matrices. </p>

<p>You can either (1) use bhSPARSE class and call its SpGEMM method in your own code, or (2) load an off-line square matrix file (*.mtx in matrix market format) as input matrix A, then benchmark C=A^2 operation. In 'main.cpp' file, see function 'test_small_spgemm()' or 'benchmark_spgemm()' for details.</p>

<p>Here are some command-line execution examples using CUDA version:</p>

<p>(1) run SpGEMM on a small matrix</p>

<p><code>./spgemm -cuda -spgemm 0</code></p>

<p>(2) run SpGEMM on poisson5pt matrices generated by CUSP</p>

<p><code>./spgemm -cuda -spgemm 1</code></p>

<p>(3) run SpGEMM on poisson9pt matrices generated by CUSP</p>

<p><code>./spgemm -cuda -spgemm 2</code></p>

<p>(4) run SpGEMM on poisson7pt matrices generated by CUSP</p>

<p><code>./spgemm -cuda -spgemm 3</code></p>

<p>(5) run SpGEMM on poisson27pt matrices generated by CUSP</p>

<p><code>./spgemm -cuda -spgemm 4</code></p>

<p>(6) run SpGEMM on a matrix loaded from a matrix market file</p>

<p><code>./spgemm -cuda -spgemm cage4.mtx</code></p>

<p>(7) run SpGEMM on a matrix loaded from a matrix market file</p>

<p><code>./spgemm -cuda -spgemm /home/username/matrices/cage4.mtx</code></p>

<p>Here are some command-line execution examples using OpenCL version:</p>

<p>(1) run SpGEMM on a small matrix</p>

<p><code>./spgemm -cuda -spgemm 0</code></p>

<p>(2) run SpGEMM on a matrix loaded from a matrix market file</p>

<p><code>./spgemm -opencl -spgemm cage4.mtx</code></p>

<p>(3) run SpGEMM on a matrix loaded from a matrix market file</p>

<p><code>./spgemm -opencl -spgemm /home/username/matrices/cage4.mtx</code></p>

<p>(4) run SpGEMM (using re-allocatable system memory of AMD APU) on a matrix loaded from a matrix market file</p>

<p><code>./spgemm -opencl-hcmp -spgemm /home/username/matrices/cage4.mtx</code></p>

<p><br></p><hr>

<h3>
<a id="precision-of-value-data-type" class="anchor" href="#precision-of-value-data-type" aria-hidden="true"><span class="octicon octicon-link"></span></a>Precision of value data type</h3>

<p>The SpGEMM supports single precision and double precision floating-point numbers. The default data type is 64-bit double precision. If 32-bit single precision is required, change <code>typedef value_type</code> in 'common.h' in the CUDA version. For the OpenCL version, change <code>typedef value_type</code> in 'common.h' and <code>typedef vT</code> in files 'SpGEMM_EM_kernels.cl', 'SpGEMM_ESC_0_1_kernels.cl', 'SpGEMM_ESC_2heap_kernels.cl', 'SpGEMM_ESC_bitonic_kernels.cl' and 'SpGEMM_copyCt2C_kernels.cl'.</p>

<p><br></p><hr>

<h3>
<a id="tested-environments" class="anchor" href="#tested-environments" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tested environments</h3>

<p>The CUDA version has been tested on nVidia GeForce GT 650M, GTX 680, GTX Titan, GTX Titan Black and GTX 980 with CUDA SDK v6.0/v6.5, CUSP v0.4.0 and multiple operating systems (Mac OS X v10.9 and Ubuntu v12.04/v14.04).</p>

<p>The OpenCL version has been tested on AMD Radeon HD 7970, R9 290X and A10-7850k APU with OpenCL v1.2/v2.0 and Ubuntu v12.04/v14.04.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">bhSPARSE maintained by <a href="https://github.com/bhSPARSE">bhSPARSE</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
