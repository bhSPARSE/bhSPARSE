<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="bhSPARSE : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>bhSPARSE</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/bhSPARSE/bhSPARSE">View on GitHub</a>

          <h1 id="project_title">bhSPARSE</h1>
          <h2 id="project_tagline"></h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/bhSPARSE/bhSPARSE/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/bhSPARSE/bhSPARSE/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="bhsparse-a-sparse-blas-library" class="anchor" href="#bhsparse-a-sparse-blas-library" aria-hidden="true"><span class="octicon octicon-link"></span></a>bhSPARSE: A Sparse BLAS Library</h1>

<p><br></p><hr>

<h3>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h3>

<p>The bhSPARSE provides basic linear algebra subroutines (BLAS) used for sparse matrix computations on heterogeneous parallel processors. Currently, the bhSPARSE library is under-developing. However, some important building blocks have their source code available.</p>

<p><br></p><hr>

<h3>
<a id="spmv-and-spgemm-for-benchmarking" class="anchor" href="#spmv-and-spgemm-for-benchmarking" aria-hidden="true"><span class="octicon octicon-link"></span></a>SpMV and SpGEMM for Benchmarking</h3>

<h5>
<a id="1-sparse-matrix-vector-multiplication-spmv-on-intel-cpus-nvidia-gpus-amd-gpus-and-intel-xeon-phi-using-the-csr5-format" class="anchor" href="#1-sparse-matrix-vector-multiplication-spmv-on-intel-cpus-nvidia-gpus-amd-gpus-and-intel-xeon-phi-using-the-csr5-format" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Sparse Matrix-Vector Multiplication (SpMV) on Intel CPUs, nVidia GPUs, AMD GPUs and Intel Xeon Phi using the CSR5 format</h5>

<p><b>Code repository</b>: <a href="https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR5"></a><a href="https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR5">https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR5</a></p>

<p><b>Paper</b>: Weifeng Liu and Brian Vinter, "CSR5: An Efficient Storage Format for Cross-Platform Sparse Matrix-Vector Multiplication". In Proceedings of the 29th ACM international conference on Supercomputing (ICS '15), pp.339-350, 2015. 
[<a href="http://www.nbi.dk/~weifeng/papers/CSR5_Liu_ics15.pdf">pdf</a>][<a href="http://www.nbi.dk/~weifeng/slides/CSR5_Liu_ics15_slides.pptx">slides</a>]</p>

<h5>
<a id="2-sparse-matrix-vector-multiplication-spmv-on-intel-amd-and-nvidia-heterogeneous-processors-using-the-csr-format" class="anchor" href="#2-sparse-matrix-vector-multiplication-spmv-on-intel-amd-and-nvidia-heterogeneous-processors-using-the-csr-format" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Sparse Matrix-Vector Multiplication (SpMV) on Intel, AMD and nVidia heterogeneous processors using the CSR format</h5>

<p><b>Code repository</b>: <a href="https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR"></a><a href="https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR">https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR</a></p>

<p><b>Paper</b>: Weifeng Liu and Brian Vinter, "Speculative Segmented Sum for Sparse Matrix-Vector Multiplication on Heterogeneous Processors". Parallel Computing, pp.179-193, Volume 49, November 2015. 
[<a href="http://www.nbi.dk/~weifeng/papers/SpMV_Liu_parco.pdf">pdf</a>]</p>

<h5>
<a id="3-sparse-matrix-matrix-multiplication-spgemm-on-gpus-and-heterogeneous-processors-using-the-csr-format" class="anchor" href="#3-sparse-matrix-matrix-multiplication-spgemm-on-gpus-and-heterogeneous-processors-using-the-csr-format" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Sparse Matrix-Matrix Multiplication (SpGEMM) on GPUs and Heterogeneous Processors using the CSR format</h5>

<p><b>Code repository</b>: <a href="https://github.com/bhSPARSE/Benchmark_SpGEMM_using_CSR"></a><a href="https://github.com/bhSPARSE/Benchmark_SpGEMM_using_CSR">https://github.com/bhSPARSE/Benchmark_SpGEMM_using_CSR</a></p>

<p><b>Paper (1)</b>: Weifeng Liu and Brian Vinter, "An Efficient GPU General Sparse Matrix-Matrix Multiplication for Irregular Data" Parallel and Distributed Processing Symposium, 2014 IEEE 28th International (IPDPS '14), pp.370-381, 19-23 May 2014. [<a href="http://www.nbi.dk/~weifeng/papers/SpGEMM_Liu_ipdps14.pdf">pdf</a>][<a href="http://www.nbi.dk/~weifeng/slides/SpGEMM_Liu_ipdps14_slides.pptx">slides</a>]</p>

<p><b>Paper (2)</b>: Weifeng Liu and Brian Vinter, "A Framework for General Sparse Matrix-Matrix Multiplication on GPUs and Heterogeneous Processors". Journal of Parallel and Distributed Computing (JPDC), pp.47-61, Volume 85, November 2015. (Extended version of the IPDPS '14 paper) [<a href="http://www.nbi.dk/~weifeng/papers/SpGEMM_Liu_jpdc.pdf">pdf</a>]</p>

<p><br></p><hr>

<h3>
<a id="contact" class="anchor" href="#contact" aria-hidden="true"><span class="octicon octicon-link"></span></a>Contact</h3>

<p><a href="http://www.nbi.dk/~weifeng/">Weifeng Liu</a> and Brian Vinter (vinter <em>at</em> nbi.ku.dk).</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">bhSPARSE maintained by <a href="https://github.com/bhSPARSE">bhSPARSE</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
